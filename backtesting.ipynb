{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f022fca1",
   "metadata": {},
   "source": [
    "# A Simple Backtesting Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b06188",
   "metadata": {},
   "source": [
    "## Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b117ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simfin.names import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Import the main functionality from the SimFin Python API.\n",
    "import simfin as sf\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "api_key = 'free'\n",
    "sf.set_api_key(api_key)\n",
    "\n",
    "root = '/Users/Wanderer/Desktop/hu/Report/' # Change this when running locally\n",
    "sf.set_data_dir(root + 'simfin_data/')\n",
    "\n",
    "bt_log = pd.DataFrame()\n",
    "        \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c253ddb5",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c287cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"us-shareprices-daily\" on disk (0 days old).\n",
      "- Loading from disk ... Done!\n",
      "Dataset \"us-income-ttm\" on disk (2 days old).\n",
      "- Loading from disk ... Done!\n",
      "Dataset \"us-balance-ttm\" on disk (2 days old).\n",
      "- Loading from disk ... Done!\n",
      "Dataset \"us-cashflow-ttm\" on disk (2 days old).\n",
      "- Loading from disk ... Done!\n",
      "Cache-file 'fin_signals-7dc370f1.pickle' on disk (0 days old).\n",
      "- Loading from disk ... Done!\n",
      "Dataset \"us-income-quarterly\" on disk (0 days old).\n",
      "- Loading from disk ... Done!\n",
      "Dataset \"us-balance-quarterly\" on disk (0 days old).\n",
      "- Loading from disk ... Done!\n",
      "Dataset \"us-cashflow-quarterly\" on disk (0 days old).\n",
      "- Loading from disk ... Done!\n",
      "Cache-file 'growth_signals-7dc370f1.pickle' on disk (0 days old).\n",
      "- Loading from disk ... Done!\n",
      "prices saved!\n",
      "incomes saved!\n",
      "balances saved!\n",
      "cashflows saved!\n",
      "finsig saved!\n",
      "growsig saved!\n"
     ]
    }
   ],
   "source": [
    "# Set testing and training endpoints:\n",
    "pre = '2015-01-01'\n",
    "mid = '2019-01-01'\n",
    "post = '2019-12-31'\n",
    "bt_bracket = 20\n",
    "\n",
    "def timecheck(price):\n",
    "    '''\n",
    "    Input: (DataFrame) data of one ticker only.\n",
    "    Output: (Boolean) True only if data begin earlier than 2015-01-01 and end later than 2019-12-31.\n",
    "    '''\n",
    "    precheck = (price.index[0] <= pd.to_datetime(pre , format = '%Y-%m-%d'))\n",
    "    postcheck = (price.index[-1] >= pd.to_datetime(post , format = '%Y-%m-%d'))\n",
    "    check = precheck & postcheck\n",
    "    return check\n",
    "\n",
    "def extracttrain(df):\n",
    "    out = df[df.index >= pd.to_datetime(pre , format = '%Y-%m-%d')]\n",
    "    out = out[out.index < pd.to_datetime(mid , format = '%Y-%m-%d')]\n",
    "    return out\n",
    "\n",
    "def extracttest(df):\n",
    "    out = df[df.index >= pd.to_datetime(mid , format = '%Y-%m-%d')]\n",
    "    out = out[out.index <= pd.to_datetime(post , format = '%Y-%m-%d')]\n",
    "    return out\n",
    "\n",
    "def tickerfilter(prices, name):\n",
    "    '''\n",
    "    Input1: (DataFrame) Data of multple tickers.\n",
    "    Input2: (str) name of the indicator.\n",
    "    Output: Writes pickle: filtered Input1\n",
    "    \n",
    "        \n",
    "    pre to mid: training\n",
    "    mid to post: testing\n",
    "    '''\n",
    "    good = sf.apply(df = prices, func = timecheck)\n",
    "    good = good[good]\n",
    "    good = list(good.index)\n",
    "    df = prices.loc[good]\n",
    "    df.to_pickle(root + 'good' + str(name) + '.pkl')\n",
    "    \n",
    "    train = sf.apply(df = df, func = extracttrain)\n",
    "    test = sf.apply(df = df, func = extracttest)\n",
    "    \n",
    "    train.to_pickle(root + 'train' + str(name) + '.pkl')\n",
    "    test.to_pickle(root + 'test' + str(name) + '.pkl')\n",
    "    print(name + ' saved!')\n",
    "    return 0\n",
    "\n",
    "def reloaddata():\n",
    "    '''\n",
    "    Loads data from SimFin.com or from local disk.\n",
    "    Writes pickle\n",
    "    '''\n",
    "    hub = sf.StockHub(market='us',\n",
    "                  refresh_days=60,\n",
    "                  refresh_days_shareprices=30)\n",
    "    \n",
    "    prices = hub.load_shareprices(variant = 'daily')\n",
    "    incomes = hub.load_income(variant = 'ttm')\n",
    "    balances = hub.load_balance(variant = 'ttm')\n",
    "    cashflows = hub.load_cashflow(variant = 'ttm')\n",
    "    \n",
    "    fin_signals = hub.fin_signals(variant='daily')\n",
    "    grow_signals = hub.growth_signals(variant='daily')\n",
    "    \n",
    "    \n",
    "    \n",
    "    tickerfilter(prices, 'prices')\n",
    "    tickerfilter(incomes, 'incomes')\n",
    "    tickerfilter(balances, 'balances')\n",
    "    tickerfilter(cashflows, 'cashflows')\n",
    "    tickerfilter(fin_signals, 'finsig')\n",
    "    tickerfilter(grow_signals, 'growsig')\n",
    "    \n",
    "##================================##\n",
    "# Last refresh on **20210614**\n",
    "# Set to True on a new device / when data is too old.\n",
    "if True:\n",
    "    reloaddata()\n",
    "##================================##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856eead",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b9960d",
   "metadata": {},
   "source": [
    "### Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19969659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function that returns the list of tickers whose average adj. close prices are at least $5.\n",
    "## Used in signal calculating.\n",
    "def overfive():\n",
    "    df = pd.read_pickle(root + 'trainprices.pkl')\n",
    "    include = df.groupby(['Ticker'])['Adj. Close'].mean()\n",
    "    include = include[include >= 5]\n",
    "    include = list(include.index)\n",
    "    return include\n",
    "\n",
    "# Backtesting:\n",
    "def topandbottom(df, text):\n",
    "    bracket = bt_bracket\n",
    "    winner = df[-bracket:]\n",
    "    loser = df[:bracket]\n",
    "    test = pd.read_pickle(root + 'testprices.pkl')\n",
    "    badstock = []\n",
    "    for stock in winner.index:\n",
    "        try:\n",
    "            winner.loc[stock,'annualret'] = test.loc[stock].iloc[-1]['Adj. Close'] / test.loc[stock].iloc[0]['Adj. Close'] - 1\n",
    "        except:\n",
    "            badstock.append(stock)\n",
    "    for stock in loser.index:\n",
    "        try:\n",
    "            loser.loc[stock,'annualret'] = test.loc[stock].iloc[-1]['Adj. Close'] / test.loc[stock].iloc[0]['Adj. Close'] - 1\n",
    "        except:\n",
    "            badstock.append(stock)\n",
    "    winner_yield = winner['annualret'].mean()\n",
    "    loser_yield = loser['annualret'].mean()\n",
    "    diff_yield = winner_yield - loser_yield\n",
    "    data = [[text, winner_yield, loser_yield, diff_yield, pre, mid, post, bracket]]\n",
    "    add = pd.DataFrame(data, columns = ['Description','Top yield','Bottom yield','Yield difference',\n",
    "                                       'Training start','Training end','Test end','Bracket'])\n",
    "    \n",
    "    global bt_log\n",
    "    bt_log = pd.concat([bt_log, add])\n",
    "    print(badstock)\n",
    "    print('According to {}, \\nthe top 100 stocks yield annually {:.4f};\\nthe bottom 100 stocks yield annually {:.4f}'.format(text,winner_yield,loser_yield))\n",
    "    \n",
    "\n",
    "def bt_prices(func, text):\n",
    "    '''\n",
    "    func: (Function) A function whose input is the price data for one ticker only.\n",
    "    name: (str) Name of the factor \n",
    "    '''\n",
    "    prices = pd.read_pickle('trainprices.pkl')\n",
    "    factors = sf.apply(df = prices, func = func)\n",
    "    factor = factors.groupby(['Ticker'])[factors.columns[-1]].mean().sort_values().dropna()\n",
    "    factor = pd.DataFrame(factor)\n",
    "    \n",
    "    topandbottom(factor, text)\n",
    "\n",
    "\n",
    "def bt_prices_grp(func, text):\n",
    "    '''\n",
    "    func: (Function) A function whose input is the price data for all tickers (GRouPed, that is).\n",
    "    name: (str) Name of the factor \n",
    "    '''\n",
    "    prices = pd.read_pickle('trainprices.pkl')\n",
    "    factors = func(prices)\n",
    "    factor = factors.groupby(['Ticker'])[factors.columns[-1]].mean().sort_values().dropna()\n",
    "    factor = pd.DataFrame(factor)\n",
    "    \n",
    "    topandbottom(factor, text)\n",
    "    \n",
    "def bt_incomes(func, text):\n",
    "    '''\n",
    "    func: (Function) A function whose input is the price data for one ticker only.\n",
    "    name: (str) Name of the factor \n",
    "    '''\n",
    "    incomes = pd.read_pickle('trainincomes.pkl')\n",
    "    factors = func(incomes)\n",
    "    factor = factors.groupby(['Ticker'])[factors.columns[-1]].mean().sort_values().dropna()\n",
    "    factor = pd.DataFrame(factor)\n",
    "    \n",
    "    topandbottom(factor, text)    \n",
    "\n",
    "def bt_signals(func, text):\n",
    "    '''\n",
    "    func: (Function) A function whose input is a financial/growth signal, for all tickers.\n",
    "    name: (str) Name of the factor \n",
    "    '''\n",
    "    factors = func()\n",
    "    factor = factors.groupby(['Ticker'])[factors.columns[-1]].mean().sort_values().dropna()\n",
    "    factor = pd.DataFrame(factor)\n",
    "    \n",
    "    topandbottom(factor, text)\n",
    "    \n",
    "def bt_prices_incomes(func, text):\n",
    "    '''\n",
    "    func: (Function) A function whose input is prices and incomes, for all tickers.\n",
    "    name: (str) Name of the factor \n",
    "    '''\n",
    "    prices = pd.read_pickle(root + 'trainprices.pkl')\n",
    "    incomes = pd.read_pickle(root + 'trainincomes.pkl')\n",
    "    factors = func(prices, incomes)\n",
    "    factor = factors.groupby(['Ticker'])[factors.columns[-1]].mean().sort_values().dropna()\n",
    "    factor = pd.DataFrame(factor)\n",
    "    \n",
    "    topandbottom(factor, text)\n",
    "    \n",
    "def bt_cashflows_incomes(func, text):\n",
    "    '''\n",
    "    func: (Function) A function whose input is cashflows and incomes, for all tickers.\n",
    "    name: (str) Name of the factor \n",
    "    '''\n",
    "    cashflows = pd.read_pickle(root + 'traincashflows.pkl')\n",
    "    incomes = pd.read_pickle(root + 'trainincomes.pkl')\n",
    "    factors = func(cashflows, incomes)\n",
    "    factor = factors.groupby(['Ticker'])[factors.columns[-1]].mean().sort_values().dropna()\n",
    "    factor = pd.DataFrame(factor)\n",
    "    \n",
    "    topandbottom(factor, text)\n",
    "\n",
    "def bt_prices_balances(func, text):\n",
    "    '''\n",
    "    func: (Function) A function whose input is prices and balances, for all tickers.\n",
    "    name: (str) Name of the factor \n",
    "    '''\n",
    "    prices = pd.read_pickle(root + 'trainprices.pkl')\n",
    "    balances = pd.read_pickle(root + 'trainbalances.pkl')\n",
    "    factors = func(prices, balances)\n",
    "    factor = factors.groupby(['Ticker'])[factors.columns[-1]].mean().sort_values().dropna()\n",
    "    factor = pd.DataFrame(factor)\n",
    "    \n",
    "    topandbottom(factor, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e9c7a",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e89fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bt_reset():\n",
    "    bt_log = pd.DataFrame()\n",
    "def bt_print():\n",
    "    bt_log.sort_values(by = ['Description','Bracket','Training start','Training end','Test end'],\n",
    "                       axis = 0, inplace = True)\n",
    "    bt_log.to_csv(root + 'backtesting_results.csv', index = False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593fccfc",
   "metadata": {},
   "source": [
    "## Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b3abd0",
   "metadata": {},
   "source": [
    "### Prices\n",
    "For single-ticker functions, test with br_prices( );  \n",
    "br_prices_grp( ) for all-tickers operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a8dfed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "According to Price: Blume & Husic (JF 1972), \n",
      "the top 100 stocks yield annually -0.0113;\n",
      "the bottom 100 stocks yield annually 8.9978\n",
      "[]\n",
      "According to Short-term Reversal: Jegadeesh (1989), \n",
      "the top 100 stocks yield annually 0.3633;\n",
      "the bottom 100 stocks yield annually -0.3060\n",
      "[]\n",
      "According to 52-Week High: George & Hwang (JF 2004), \n",
      "the top 100 stocks yield annually -0.0622;\n",
      "the bottom 100 stocks yield annually 7.9244\n",
      "[]\n",
      "According to Max: Bali et al. (JF 2010), \n",
      "the top 100 stocks yield annually 0.0976;\n",
      "the bottom 100 stocks yield annually 5.5009\n",
      "[]\n",
      "According to Amihud's Measure: Amihud (JFM 2002), \n",
      "the top 100 stocks yield annually -0.1688;\n",
      "the bottom 100 stocks yield annually 0.0080\n",
      "[]\n",
      "According to Size: Banz (JFE 1981), \n",
      "the top 100 stocks yield annually 0.3136;\n",
      "the bottom 100 stocks yield annually 6.8649\n"
     ]
    }
   ],
   "source": [
    "def logprice(prices):\n",
    "    '''\n",
    "    Price\n",
    "    Blume & Husic (JF 1972)\n",
    "    '''\n",
    "    logprice = pd.DataFrame()\n",
    "    logprice['logprice'] = prices['Adj. Close'].apply(lambda x: np.log(x))\n",
    "    prices = pd.concat([prices, logprice], axis = 1, join = 'inner')\n",
    "    return prices\n",
    "\n",
    "bt_prices(logprice, 'Price: Blume & Husic (JF 1972)')\n",
    "\n",
    "# Long-term reversal is unavailable for any two-year training dataset \n",
    "## for the obvious reason that two years is not really \"long term\".\n",
    "'''\n",
    "def longreversal(prices):\n",
    "    ''''''\n",
    "    Long-term Reversal\n",
    "    Debondt and Thaler (JF 1985)\n",
    "    ''''''\n",
    "    longrev = sf.asfreq(df = prices, freq = 'D', method = 'ffill')\n",
    "    longrev['longreversal'] = longrev['Adj. Close'].pct_change(1410).shift(390)\n",
    "    longrev = longrev['longreversal']\n",
    "    prices = pd.concat([prices, longrev], axis = 1, join = 'inner')\n",
    "    return prices\n",
    "\n",
    "bt_prices(longreversal, 'Long-term Reversal: Debondt and Thaler (JF 1985)')\n",
    "'''\n",
    "\n",
    "def shortreversal(prices):\n",
    "    '''\n",
    "    Short-term Reversal\n",
    "    Jegadeesh (1989)\n",
    "    '''\n",
    "    shortrev = sf.asfreq(df = prices, freq = 'D', method = 'ffill')\n",
    "    shortrev['shortreversal'] = prices['Adj. Close'].pct_change(30)\n",
    "    shortrev['shortreversal_ex'] = (prices['Adj. Close'].mean() < 5)\n",
    "    shortrev = shortrev[['shortreversal','shortreversal_ex']]\n",
    "    shortrev = shortrev[shortrev['shortreversal_ex'] == False]\n",
    "    prices = pd.concat([prices, shortrev['shortreversal']], axis = 1, join = 'inner')\n",
    "    return prices\n",
    "\n",
    "bt_prices(shortreversal, 'Short-term Reversal: Jegadeesh (1989)')\n",
    "\n",
    "def yearhigh(prices):\n",
    "    '''\n",
    "    52-Week High\n",
    "    George & Hwang (JF 2004)\n",
    "    '''\n",
    "    pricefilled = sf.asfreq(df = prices, freq='D', method='ffill')\n",
    "    pricefilled.rename(columns = {'Adj. Close':'yearhigh'}, inplace = True)\n",
    "    yearhigh = pricefilled['yearhigh'].rolling(window = '364D').max()\n",
    "    prices = pd.concat([prices, yearhigh], axis = 1, join = 'inner')\n",
    "    return prices\n",
    "\n",
    "bt_prices(yearhigh, '52-Week High: George & Hwang (JF 2004)')\n",
    "\n",
    "def monthmax(prices):\n",
    "    '''\n",
    "    Max\n",
    "    Bali et al. (JF 2010)\n",
    "    '''\n",
    "    pricefilled = sf.asfreq(df = prices, freq = 'D', method = 'ffill')\n",
    "    pricefilled.rename(columns = {'Adj. Close':'max'}, inplace = True)\n",
    "    returns = pricefilled['max'].pct_change()\n",
    "    maxreturns = returns.rolling(window = '30D').max()\n",
    "    prices = pd.concat([prices, maxreturns], axis = 1, join = 'inner')\n",
    "    return prices\n",
    "\n",
    "\n",
    "bt_prices(monthmax, 'Max: Bali et al. (JF 2010)')\n",
    "\n",
    "def amihud(prices):\n",
    "    '''\n",
    "    Amihud's Measure\n",
    "    Amihud (JFM 2002)\n",
    "    '''\n",
    "    amihud = pd.DataFrame()\n",
    "    amihud['raw'] = (prices['Adj. Close'].diff()) * prices['Volume'] * prices['Adj. Close']\n",
    "    amihud['Amihud'] = amihud['raw'].rolling(window = \"365D\").mean()\n",
    "    amihud['Amihud_ex'] = (prices['Adj. Close'].mean() < 5)\n",
    "    amihud = amihud[['Amihud','Amihud_ex']]\n",
    "    amihud = amihud[amihud['Amihud_ex'] == False]\n",
    "    prices = pd.concat([prices, amihud['Amihud']], axis = 1, join = 'inner')\n",
    "    return prices\n",
    "\n",
    "bt_prices(amihud, 'Amihud\\'s Measure: Amihud (JFM 2002)')\n",
    "\n",
    "def equitysize(prices):\n",
    "    '''\n",
    "    Size\n",
    "    Banz (JFE 1981)\n",
    "    (Or market capitalization)\n",
    "    '''\n",
    "    eqsize = pd.DataFrame()\n",
    "    eqsize['size'] = prices['Adj. Close'] * prices['Shares Outstanding']\n",
    "    eqsize['size'] = eqsize['size'].apply(lambda x: np.log(x))\n",
    "    prices = pd.concat([prices, eqsize], axis = 1, join = 'inner')\n",
    "    return prices\n",
    "\n",
    "bt_prices(equitysize, 'Size: Banz (JFE 1981)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "185a2c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "According to Firm Age: Barry and Brown (JFE 1984), \n",
      "the top 100 stocks yield annually 0.1222;\n",
      "the bottom 100 stocks yield annually 0.2477\n"
     ]
    }
   ],
   "source": [
    "# An exception, in that it does not actually use the training data, \n",
    "## but records the \"earliest observation\" in the whole dataset.\n",
    "## The input, therefore, is redundant in itself, but necessary for fitting into the backtesting function.\n",
    "def age(prices):\n",
    "    '''\n",
    "    Firm Age\n",
    "    Barry and Brown (JFE 1984)\n",
    "    '''\n",
    "    df = pd.read_pickle(root + 'goodprices.pkl')\n",
    "    def getage(price):\n",
    "        birthday = price.index[0]\n",
    "        output = -12 * (birthday.year - 2015) - (birthday.month)\n",
    "        if price['Adj. Close'].mean() < 5:\n",
    "            output = np.NaN\n",
    "        output = pd.DataFrame([[output]])\n",
    "        return output\n",
    "    out = sf.apply(df = df, func = getage)\n",
    "    out = out.reset_index(level = 1)\n",
    "    return out\n",
    "\n",
    "bt_prices_grp(age, 'Firm Age: Barry and Brown (JFE 1984)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363946f7",
   "metadata": {},
   "source": [
    "### Signals\n",
    "Test with bt_signals( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4574225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "According to Asset Turnover: Soliman (AR 2008), \n",
      "the top 100 stocks yield annually 0.0821;\n",
      "the bottom 100 stocks yield annually 0.1573\n",
      "[]\n",
      "According to Asset Growth: Cooper et al. (JF 2008), \n",
      "the top 100 stocks yield annually 0.2780;\n",
      "the bottom 100 stocks yield annually 0.2578\n",
      "[]\n",
      "According to Sales Growth: LSV (JF 1994), \n",
      "the top 100 stocks yield annually 0.5321;\n",
      "the bottom 100 stocks yield annually 0.1388\n",
      "[]\n",
      "According to Profit Margin: Soliman (AR 2008), \n",
      "the top 100 stocks yield annually 0.4403;\n",
      "the bottom 100 stocks yield annually 0.2057\n",
      "[]\n",
      "According to Return on Assets: DuPont, \n",
      "the top 100 stocks yield annually 0.3445;\n",
      "the bottom 100 stocks yield annually 0.0431\n",
      "[]\n",
      "According to Return on Equity: Haugen and Baker (JFE 1996), \n",
      "the top 100 stocks yield annually 0.0509;\n",
      "the bottom 100 stocks yield annually 0.2591\n"
     ]
    }
   ],
   "source": [
    "def assetturnover():\n",
    "    '''\n",
    "    Asset Turnover\n",
    "    Soliman (AR 2008)\n",
    "    '''\n",
    "    include = overfive()\n",
    "    finsig = pd.read_pickle(root + 'trainfinsig.pkl')\n",
    "    out = finsig.loc[include]\n",
    "    out = out[['Asset Turnover']]\n",
    "    return out\n",
    "\n",
    "bt_signals(assetturnover, 'Asset Turnover: Soliman (AR 2008)')\n",
    "\n",
    "def assetgrowth():\n",
    "    '''\n",
    "    Asset Growth\n",
    "    Cooper et al. (JF 2008)\n",
    "    '''\n",
    "    growsig = pd.read_pickle(root + 'traingrowsig.pkl')\n",
    "    out = growsig[['Assets Growth']]\n",
    "    return out\n",
    "\n",
    "bt_signals(assetgrowth, 'Asset Growth: Cooper et al. (JF 2008)')\n",
    "\n",
    "def salesgrowth():\n",
    "    '''\n",
    "    Sales Growth\n",
    "    LSV (JF 1994)\n",
    "    '''\n",
    "    growsig = pd.read_pickle(root + 'traingrowsig.pkl')\n",
    "    out = growsig[['Sales Growth']]\n",
    "    return out\n",
    "\n",
    "bt_signals(salesgrowth, 'Sales Growth: LSV (JF 1994)')\n",
    "\n",
    "def profitmargin():\n",
    "    '''\n",
    "    Profit Margin\n",
    "    Soliman (AR 2008)\n",
    "    '''\n",
    "    include = overfive()\n",
    "    finsig = pd.read_pickle(root + 'trainfinsig.pkl')\n",
    "    out = finsig.loc[include]\n",
    "    out = out[['Net Profit Margin']]\n",
    "    return out\n",
    "\n",
    "bt_signals(profitmargin, 'Profit Margin: Soliman (AR 2008)')\n",
    "\n",
    "def roa():\n",
    "    '''\n",
    "    Return on Assets\n",
    "    DuPont\n",
    "    '''\n",
    "    include = overfive()\n",
    "    finsig = pd.read_pickle(root + 'trainfinsig.pkl')\n",
    "    out = finsig.loc[include]\n",
    "    out = out[['Return on Assets']]\n",
    "    return out\n",
    "\n",
    "bt_signals(roa, 'Return on Assets: DuPont')\n",
    "\n",
    "def roe():\n",
    "    '''\n",
    "    Return on Equity\n",
    "    Haugen and Baker (JFE 1996)\n",
    "    '''\n",
    "    include = overfive()\n",
    "    finsig = pd.read_pickle(root + 'trainfinsig.pkl')\n",
    "    out = finsig.loc[include]\n",
    "    out = out[['Return on Equity']]\n",
    "    return out\n",
    "\n",
    "bt_signals(roe, 'Return on Equity: Haugen and Baker (JFE 1996)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d7477a",
   "metadata": {},
   "source": [
    "### Incomes\n",
    "Test with bt_incomes( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e289a1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "According to Earnings Consistency, Alwathainani (BAR 2009), \n",
      "the top 100 stocks yield annually 0.2333;\n",
      "the bottom 100 stocks yield annually -0.2174\n"
     ]
    }
   ],
   "source": [
    "def earnings_consistency(incomes):\n",
    "    '''\n",
    "    Earnings Consistency\n",
    "    Alwathainani (BAR 2009)\n",
    "    '''\n",
    "    include = overfive()\n",
    "    income = incomes[incomes.index.get_level_values('Ticker').isin(include)]\n",
    "    income.loc[:,'Earnings per Share'] = income['Net Income (Common)'] / income['Shares (Diluted)']\n",
    "    income.loc[:,'Earnings Consistency'] = income['Earnings per Share'].diff() / (abs(income['Earnings per Share'].shift(1)) + abs(income['Earnings per Share'].shift(2)) / 2)\n",
    "    output = income[['Earnings Consistency']]\n",
    "    return output\n",
    "\n",
    "bt_incomes(earnings_consistency, 'Earnings Consistency, Alwathainani (BAR 2009)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743bc5",
   "metadata": {},
   "source": [
    "### Cashflows and Incomes\n",
    "Test with bt_cashflows_incomes( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7321227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UPL', 'CRR', 'CHK', 'RHE', 'CMBG']\n",
      "According to Investment: Titman, Wei, and Xie (JFQA 2004), \n",
      "the top 100 stocks yield annually 0.0491;\n",
      "the bottom 100 stocks yield annually 0.2067\n"
     ]
    }
   ],
   "source": [
    "def investment(cashflows, incomes):\n",
    "    '''\n",
    "    Investment\n",
    "    Titman, Wei, and Xie (JFQA 2004)\n",
    "    '''\n",
    "    df = pd.merge(cashflows[CAPEX],\n",
    "                  incomes[REVENUE],\n",
    "                  on=['Ticker','Report Date'])\n",
    "    df['investment'] = df[CAPEX]/df[REVENUE]\n",
    "    return df\n",
    "\n",
    "bt_cashflows_incomes(investment, 'Investment: Titman, Wei, and Xie (JFQA 2004)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753c71e5",
   "metadata": {},
   "source": [
    "### Prices and Balances\n",
    "Test with bt_prices_balances( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f1422ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "According to Leverage: Bhandari (JFE 1988), \n",
      "the top 100 stocks yield annually 0.1593;\n",
      "the bottom 100 stocks yield annually 0.0894\n"
     ]
    }
   ],
   "source": [
    "def leverage(prices, balances):\n",
    "    '''\n",
    "    Leverage\n",
    "    Bhandari (JFE 1988)\n",
    "    '''\n",
    "    # Log of Long Term Debt\n",
    "    balance=balances.fillna(1)\n",
    "    balance = balances.fillna(1)\n",
    "    balance['Log of Long Term Debt'] = np.log(balance['Long Term Debt'])\n",
    "\n",
    "    balance = balance.reset_index(level=1)\n",
    "    balance = balance.rename(columns = {'Report Date':'Date'})\n",
    "\n",
    "    # Market Value of Equity\n",
    "    price = prices.reset_index(level = 1)\n",
    "    price['Market Value of Equity'] = price['Adj. Close'] * price['Shares Outstanding']\n",
    "\n",
    "    df = pd.merge(balance[['Date','Log of Long Term Debt']],\n",
    "                  price[['Date','Market Value of Equity']],\n",
    "                  on=['Ticker','Date'])\n",
    "\n",
    "    df['Leverage'] = df['Log of Long Term Debt'] / df['Market Value of Equity']\n",
    "    \n",
    "    return df\n",
    "\n",
    "bt_prices_balances(leverage, 'Leverage: Bhandari (JFE 1988)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f1e69",
   "metadata": {},
   "source": [
    "### Prices and Incomes\n",
    "Test with bt_prices_incomes( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "890be0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "According to Cash Flow Variance: Haugen and Baker (JFE 1996), \n",
      "the top 100 stocks yield annually 0.2513;\n",
      "the bottom 100 stocks yield annually 0.3213\n"
     ]
    }
   ],
   "source": [
    "def cashflowvar(prices, incomes):\n",
    "    '''\n",
    "    Cash Flow Variance\n",
    "    Haugen and Baker (JFE 1996)\n",
    "    '''\n",
    "    \n",
    "    # Market Value of Equity\n",
    "    include = overfive()\n",
    "    price = prices.loc[include]\n",
    "    price = price.reset_index(level=0)\n",
    "    price = price.groupby(['Ticker']).resample('Q').mean()\n",
    "    price['Market Value of Equity'] = price['Adj. Close'] * price['Shares Outstanding']\n",
    "    price = price.reset_index(level=1)\n",
    "    \n",
    "    # Cash Flow Variance\n",
    "    income = incomes.reset_index(level=1)\n",
    "    income = income.fillna(0)\n",
    "    income = income.rename(columns = {'Report Date':'Date'})\n",
    "\n",
    "    cashflow = pd.merge(price[['Date','Market Value of Equity']],\n",
    "                         income[['Date','Depreciation & Amortization','Net Income']],\n",
    "                         on=['Ticker','Date'])\n",
    "    cashflow['Cash Flow Variance'] = (cashflow['Net Income'] + cashflow['Depreciation & Amortization']) / cashflow['Market Value of Equity']\n",
    "    cashflow['Ticker'] = cashflow.index\n",
    "    cashflow.set_index('Date', drop=True, append=False, inplace=True)\n",
    "    cashflow = cashflow.groupby('Ticker').resample('Y').var()\n",
    "    \n",
    "    return cashflow[['Cash Flow Variance']]\n",
    "\n",
    "bt_prices_incomes(cashflowvar, 'Cash Flow Variance: Haugen and Baker (JFE 1996)')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0be00870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "According to Share volume, \n",
      "the top 100 stocks yield annually 0.4080;\n",
      "the bottom 100 stocks yield annually 5.6639\n"
     ]
    }
   ],
   "source": [
    "def Share_Volume(volume):\n",
    "    volume = volume.resample('M').mean()\n",
    "    volume['Share_Volume'] = volume['Volume'].rolling(window=3).mean()\n",
    "    return volume\n",
    "\n",
    "bt_prices(Share_Volume, 'Share volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a002343",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
